"""empty message

Revision ID: fdca45917983
Revises: cedcb4b94fed
Create Date: 2026-01-20 11:35:59.324243

"""

from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql
import pgvector


# revision identifiers, used by Alembic.
revision: str = "fdca45917983"
down_revision: Union[str, Sequence[str], None] = "cedcb4b94fed"
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.execute("CREATE EXTENSION IF NOT EXISTS vector;")
    op.create_table(
        "learning_plans",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("user_id", sa.Integer(), nullable=False),
        sa.Column("name", sa.String(), nullable=False),
        sa.Column("description", sa.Text(), nullable=True),
        sa.Column(
            "courses", postgresql.JSONB(astext_type=sa.Text()), nullable=False
        ),
        sa.Column("is_active", sa.Boolean(), nullable=True),
        sa.Column(
            "created_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("now()"),
            nullable=True,
        ),
        sa.Column("updated_at", sa.DateTime(timezone=True), nullable=True),
        sa.ForeignKeyConstraint(
            ["user_id"],
            ["users.id"],
            name=op.f("fk_learning_plans_user_id_users"),
        ),
        sa.PrimaryKeyConstraint("id", name=op.f("pk_learning_plans")),
    )
    op.create_index(
        op.f("ix_learning_plans_id"), "learning_plans", ["id"], unique=False
    )
    op.create_table(
        "solution_analyses",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("user_id", sa.Integer(), nullable=False),
        sa.Column("task_id", sa.Integer(), nullable=False),
        sa.Column("image_file_id", sa.Integer(), nullable=False),
        sa.Column(
            "analysis_result",
            postgresql.JSONB(astext_type=sa.Text()),
            nullable=True,
        ),
        sa.Column("status", sa.String(), nullable=True),
        sa.Column(
            "created_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("now()"),
            nullable=True,
        ),
        sa.Column("completed_at", sa.DateTime(timezone=True), nullable=True),
        sa.ForeignKeyConstraint(
            ["image_file_id"],
            ["files.id"],
            name=op.f("fk_solution_analyses_image_file_id_files"),
        ),
        sa.ForeignKeyConstraint(
            ["task_id"],
            ["tasks.id"],
            name=op.f("fk_solution_analyses_task_id_tasks"),
        ),
        sa.ForeignKeyConstraint(
            ["user_id"],
            ["users.id"],
            name=op.f("fk_solution_analyses_user_id_users"),
        ),
        sa.PrimaryKeyConstraint("id", name=op.f("pk_solution_analyses")),
    )
    op.create_index(
        op.f("ix_solution_analyses_id"),
        "solution_analyses",
        ["id"],
        unique=False,
    )
    op.add_column(
        "background_jobs", sa.Column("progress", sa.Integer(), nullable=True)
    )
    op.add_column(
        "background_jobs", sa.Column("error_message", sa.Text(), nullable=True)
    )
    op.add_column(
        "background_jobs",
        sa.Column("retry_count", sa.Integer(), nullable=True),
    )
    op.add_column(
        "background_jobs",
        sa.Column("max_retries", sa.Integer(), nullable=True),
    )
    op.add_column(
        "background_jobs", sa.Column("queue_name", sa.String(), nullable=True)
    )
    op.add_column(
        "courses", sa.Column("source_type", sa.String(), nullable=True)
    )
    op.add_column(
        "courses",
        sa.Column(
            "source_data",
            postgresql.JSONB(astext_type=sa.Text()),
            nullable=True,
        ),
    )
    op.add_column(
        "courses", sa.Column("is_verified", sa.Boolean(), nullable=True)
    )
    op.add_column(
        "courses",
        sa.Column(
            "embedding",
            pgvector.sqlalchemy.vector.VECTOR(dim=1536),
            nullable=True,
        ),
    )
    op.add_column(
        "courses", sa.Column("created_by", sa.Integer(), nullable=True)
    )
    op.add_column(
        "courses", sa.Column("rating_count", sa.Integer(), nullable=True)
    )
    op.create_foreign_key(
        op.f("fk_courses_created_by_users"),
        "courses",
        "users",
        ["created_by"],
        ["id"],
    )
    op.add_column("files", sa.Column("file_type", sa.String(), nullable=True))
    op.add_column(
        "files", sa.Column("processing_status", sa.String(), nullable=True)
    )
    op.add_column(
        "files", sa.Column("extracted_text", sa.Text(), nullable=True)
    )
    op.add_column(
        "files",
        sa.Column(
            "file_metadata",
            postgresql.JSONB(astext_type=sa.Text()),
            nullable=True,
        ),
    )
    op.drop_column("files", "type")
    op.add_column(
        "tasks", sa.Column("difficulty", sa.Integer(), nullable=True)
    )
    op.add_column("tasks", sa.Column("explanation", sa.Text(), nullable=True))
    op.add_column(
        "tasks",
        sa.Column("tags", postgresql.ARRAY(sa.String()), nullable=True),
    )
    op.add_column(
        "tasks", sa.Column("requires_ai_check", sa.Boolean(), nullable=True)
    )
    op.add_column(
        "tasks", sa.Column("file_upload_allowed", sa.Boolean(), nullable=True)
    )
    op.add_column(
        "user_limits",
        sa.Column("course_generation_limit", sa.Integer(), nullable=True),
    )
    op.add_column(
        "user_limits",
        sa.Column("course_generation_used", sa.Integer(), nullable=True),
    )
    op.add_column(
        "user_limits",
        sa.Column(
            "course_generation_reset_at",
            sa.DateTime(timezone=True),
            nullable=True,
        ),
    )
    op.add_column(
        "user_limits",
        sa.Column("ai_explanation_limit", sa.Integer(), nullable=True),
    )
    op.add_column(
        "user_limits",
        sa.Column("ai_explanation_used", sa.Integer(), nullable=True),
    )
    op.add_column(
        "users", sa.Column("telegram_chat_id", sa.BigInteger(), nullable=True)
    )
    op.add_column(
        "users", sa.Column("telegram_username", sa.String(), nullable=True)
    )
    op.add_column(
        "users",
        sa.Column(
            "notification_preferences",
            postgresql.JSONB(astext_type=sa.Text()),
            nullable=True,
        ),
    )
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_column("users", "notification_preferences")
    op.drop_column("users", "telegram_username")
    op.drop_column("users", "telegram_chat_id")
    op.drop_column("user_limits", "ai_explanation_used")
    op.drop_column("user_limits", "ai_explanation_limit")
    op.drop_column("user_limits", "course_generation_reset_at")
    op.drop_column("user_limits", "course_generation_used")
    op.drop_column("user_limits", "course_generation_limit")
    op.drop_column("tasks", "file_upload_allowed")
    op.drop_column("tasks", "requires_ai_check")
    op.drop_column("tasks", "tags")
    op.drop_column("tasks", "explanation")
    op.drop_column("tasks", "difficulty")
    op.add_column(
        "files",
        sa.Column("type", sa.VARCHAR(), autoincrement=False, nullable=False),
    )
    op.drop_column("files", "file_metadata")
    op.drop_column("files", "extracted_text")
    op.drop_column("files", "processing_status")
    op.drop_column("files", "file_type")
    op.drop_constraint(
        op.f("fk_courses_created_by_users"), "courses", type_="foreignkey"
    )
    op.drop_column("courses", "rating_count")
    op.drop_column("courses", "created_by")
    op.drop_column("courses", "embedding")
    op.drop_column("courses", "is_verified")
    op.drop_column("courses", "source_data")
    op.drop_column("courses", "source_type")
    op.drop_column("background_jobs", "queue_name")
    op.drop_column("background_jobs", "max_retries")
    op.drop_column("background_jobs", "retry_count")
    op.drop_column("background_jobs", "error_message")
    op.drop_column("background_jobs", "progress")
    op.drop_index(
        op.f("ix_solution_analyses_id"), table_name="solution_analyses"
    )
    op.drop_table("solution_analyses")
    op.drop_index(op.f("ix_learning_plans_id"), table_name="learning_plans")
    op.drop_table("learning_plans")
    op.execute("DROP EXTENSION IF EXISTS vector;")
    # ### end Alembic commands ###
